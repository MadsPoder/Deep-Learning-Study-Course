{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madspoderpetersen/deep-traffic/venv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "import keras.preprocessing.image\n",
    "import keras_retinanet\n",
    "import math\n",
    "from keras_retinanet import models, losses\n",
    "from keras_retinanet.models.retinanet import retinanet_bbox\n",
    "from keras_retinanet.models.resnet import resnet50_retinanet\n",
    "from keras_retinanet.preprocessing.csv_generator import CSVGenerator\n",
    "#from generator import CustomCSVGenerator\n",
    "from keras_retinanet.callbacks import RedirectModel\n",
    "#from keras_retinanet.callbacks.eval import Evaluate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from shared import get_session, TrainingType\n",
    "from callbacks import save_weights_vis, Evaluate\n",
    "from paths import *\n",
    "\n",
    "#Create folders\n",
    "if not os.path.exists(SNAPSHOTS_DIR):\n",
    "    os.makedirs(SNAPSHOTS_DIR)\n",
    "    \n",
    "if not os.path.exists(LOGS_DIR):\n",
    "    os.makedirs(LOGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(num_classes, weights, freeze_backbone=None):\n",
    "    modifier = freeze_model if freeze_backbone else None\n",
    "    model = models.resnet.resnet_retinanet(num_classes, modifier=modifier)\n",
    "    if weights == \"imagenet\":\n",
    "        backbone = models.backbone('resnet50')\n",
    "        imgnet_weights = backbone.download_imagenet()\n",
    "        #Load by_name only inputs into the resnet backbone (Tak Thomas)\n",
    "        model.load_weights(imgnet_weights, skip_mismatch=True, by_name=True)\n",
    "    elif weights:\n",
    "        model.load_weights(weights, skip_mismatch=True)\n",
    "\n",
    "    prediction_model = retinanet_bbox(model=model)\n",
    "    \n",
    "    model.trainable = True\n",
    "\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True \n",
    "\n",
    "    model.compile(\n",
    "        loss={\n",
    "            'regression'    : losses.smooth_l1(),\n",
    "            'classification': losses.focal()\n",
    "        },\n",
    "        optimizer=keras.optimizers.adam(lr=1e-3, clipnorm=0.001),\n",
    "        \n",
    "    )\n",
    "    #metrics=['accuracy'] kan inkluderes i model.compile\n",
    "    \n",
    "    model.trainable = True\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True \n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    return model, prediction_model\n",
    "\n",
    "def create_train_generator(batch_size):\n",
    "    train_generator = CSVGenerator(\n",
    "        TRAIN_GROUND_TRUTH,\n",
    "        CLASS_MAPPINGS,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return train_generator\n",
    "\n",
    "def create_test_generator(batch_size):\n",
    "    test_generator = CSVGenerator(\n",
    "        TEST_GROUND_TRUTH,\n",
    "        CLASS_MAPPINGS,\n",
    "        shuffle_groups=False,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return test_generator\n",
    "\n",
    "def create_callbacks(model, prediction_model, batch_size, test_generator, train_generator, resume):\n",
    "    callbacks = []\n",
    "\n",
    "    # save the prediction model\n",
    "    if resume:\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(os.path.join(SNAPSHOTS_DIR, 'custom_resnet50_lolle_resume_imgnet_{epoch:02d}.h5'), verbose=1, period=5)\n",
    "    else:\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(os.path.join(SNAPSHOTS_DIR, 'custom_resnet50_imgnet_{epoch:02d}.h5'), verbose=1, period=5)\n",
    "\n",
    "    #checkpoint = RedirectModel(checkpoint, model)\n",
    "    callbacks.append(checkpoint)\n",
    "    \n",
    "    #Visualisation of weights\n",
    "    vis_weights = None\n",
    "    if resume:\n",
    "        vis_weights = save_weights_vis(os.path.join(SNAPSHOTS_DIR, 'custom_resnet50_resume_imgnet_{}.png'))\n",
    "    else:\n",
    "        vis_weights = save_weights_vis(os.path.join(SNAPSHOTS_DIR, 'custom_resnet50_imgnet_{}.png'))\n",
    "    callbacks.append(vis_weights)\n",
    "    \n",
    "    #Reduce learning rate on plateu (tidligere loss, val_loss)\n",
    "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, verbose=1, mode='auto', cooldown=0, min_lr=0.001)\n",
    "    #callbacks.append(lr_scheduler)\n",
    "    \n",
    "    #Early stop\n",
    "    early_stop = EarlyStopping(monitor='loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "    callbacks.append(early_stop)\n",
    "    \n",
    "    #For tensorboard\n",
    "    tensorboard_callb = keras.callbacks.TensorBoard(log_dir=LOGS_DIR, histogram_freq=0, batch_size=batch_size, \n",
    "                                                    write_graph=True, write_grads=False, write_images=True, \n",
    "                                                    embeddings_freq=0, embeddings_layer_names=None, \n",
    "                                                    embeddings_metadata=None)\n",
    "    callbacks.append(tensorboard_callb)\n",
    "    \n",
    "    #Evaluation for the test/train set\n",
    "    evaluation_test = Evaluate(test_generator, tensorboard=tensorboard_callb, verbose=0, train=False)\n",
    "    evaluation_test = RedirectModel(evaluation_test, prediction_model)\n",
    "    callbacks.append(evaluation_test)\n",
    "    evaluation_train = Evaluate(train_generator, tensorboard=tensorboard_callb, verbose=0, train=True)\n",
    "    evaluation_train = RedirectModel(evaluation_train, prediction_model)\n",
    "    callbacks.append(evaluation_train)\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/madspoderpetersen/deep-traffic/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Epoch 1/75\n",
      "105/151 [===================>..........] - ETA: 57s - loss: 5.0849 - regression_loss: 3.7777 - classification_loss: 1.3072"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "training_type = TrainingType.IMGNET\n",
    "batch_size = 4\n",
    "\n",
    "keras.backend.tensorflow_backend.set_session(get_session())\n",
    "train_generator = create_train_generator(batch_size)\n",
    "test_generator = create_test_generator(batch_size)\n",
    "resume = False\n",
    "\n",
    "#From start\n",
    "if training_type == TrainingType.SCRATCH:\n",
    "    model, prediction_model = create_models(num_classes=train_generator.num_classes(), weights=None)\n",
    "#From imagenet\n",
    "elif training_type == TrainingType.IMGNET:\n",
    "    model, prediction_model = create_models(num_classes=train_generator.num_classes(), weights=\"imagenet\")\n",
    "#From earlier \n",
    "elif training_type == TrainingType.RESUME:\n",
    "    #snapshot = os.path.join(SNAPSHOTS_DIR, \"custom_resnet50_10.h5\")\n",
    "    snapshot = os.path.join(SNAPSHOTS_DIR, \"custom_resnet50_lolle_06.h5\")\n",
    "    resume = True\n",
    "    model, prediction_model = create_models(num_classes=train_generator.num_classes(), weights=snapshot)\n",
    "\n",
    "callbacks = create_callbacks(model, prediction_model, batch_size, test_generator, train_generator, resume)\n",
    "\n",
    "model.trainable = True\n",
    "\n",
    "# start training\n",
    "model.fit_generator(\n",
    "    generator = train_generator,\n",
    "    #steps_per_epoch = 850,\n",
    "    steps_per_epoch = math.floor(train_generator.size()/batch_size),\n",
    "    epochs = 75,\n",
    "    verbose = 1,\n",
    "    #workers=6,\n",
    "    #validation_data=test_generator,\n",
    "    #validation_steps=math.floor(test_generator.size()/batch_size),\n",
    "    callbacks = callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras_retinanet.models import load_model, backbone, resnet\n",
    "from keras_retinanet.utils.image import read_image_bgr\n",
    "from shared import get_session\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Get weights from conv1 layer\n",
    "weights = np.asarray(model.get_layer('conv1').get_weights())\n",
    "fig, ax = plt.subplots(figsize=(10, 10),nrows=8, ncols=8)\n",
    "for i, ax in enumerate(ax.reshape(-1)):\n",
    "    imgArray = weights[0,:,:,:,i]\n",
    "    # unity-based normalization https://datascience.stackexchange.com/a/5888\n",
    "    imgArray = (imgArray - np.min(imgArray)) / (np.max(imgArray) - np.min(imgArray))\n",
    "    ax.imshow(imgArray)\n",
    "    ax.axis('off')\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
