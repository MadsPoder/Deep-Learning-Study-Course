{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madspoderpetersen/deep-traffic/venv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "import keras.preprocessing.image\n",
    "import keras_retinanet\n",
    "import math\n",
    "from keras_retinanet import models, losses\n",
    "from keras_retinanet.models.retinanet import retinanet_bbox\n",
    "from keras_retinanet.models.resnet import resnet50_retinanet\n",
    "from keras_retinanet.preprocessing.csv_generator import CSVGenerator\n",
    "#from generator import CustomCSVGenerator\n",
    "from keras_retinanet.callbacks import RedirectModel\n",
    "#from keras_retinanet.callbacks.eval import Evaluate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from shared import get_session, TrainingType\n",
    "from callbacks import save_weights_vis, Evaluate\n",
    "from paths import *\n",
    "\n",
    "#Create folders\n",
    "if not os.path.exists(SNAPSHOTS_DIR):\n",
    "    os.makedirs(SNAPSHOTS_DIR)\n",
    "    \n",
    "if not os.path.exists(LOGS_DIR):\n",
    "    os.makedirs(LOGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(num_classes, weights, freeze_backbone=None):\n",
    "    modifier = freeze_model if freeze_backbone else None\n",
    "    model = models.resnet.resnet_retinanet(num_classes, modifier=modifier)\n",
    "    if weights == \"imagenet\":\n",
    "        backbone = models.backbone('resnet50')\n",
    "        imgnet_weights = backbone.download_imagenet()\n",
    "        #Load by_name only inputs into the resnet backbone (Tak Thomas)\n",
    "        model.load_weights(imgnet_weights, skip_mismatch=True, by_name=True)\n",
    "    elif weights:\n",
    "        model.load_weights(weights, skip_mismatch=True)\n",
    "\n",
    "    prediction_model = retinanet_bbox(model=model)\n",
    "    \n",
    "    model.trainable = True\n",
    "\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True \n",
    "\n",
    "    model.compile(\n",
    "        loss={\n",
    "            'regression'    : losses.smooth_l1(),\n",
    "            'classification': losses.focal()\n",
    "        },\n",
    "        optimizer=keras.optimizers.adam(lr=1e-5, clipnorm=0.001),\n",
    "        \n",
    "    )\n",
    "    #metrics=['accuracy'] kan inkluderes i model.compile\n",
    "    \n",
    "    model.trainable = True\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True \n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    return model, prediction_model\n",
    "\n",
    "def create_train_generator(batch_size):\n",
    "    train_generator = CSVGenerator(\n",
    "        TRAIN_GROUND_TRUTH_COMBINED,\n",
    "        CLASS_MAPPINGS_COMBINED,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return train_generator\n",
    "\n",
    "def create_test_generator(batch_size):\n",
    "    test_generator = CSVGenerator(\n",
    "        TEST_GROUND_TRUTH_COMBINED,\n",
    "        CLASS_MAPPINGS_COMBINED,\n",
    "        shuffle_groups=False,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return test_generator\n",
    "\n",
    "def create_callbacks(model, prediction_model, batch_size, test_generator, train_generator, resume):\n",
    "    callbacks = []\n",
    "\n",
    "    # save the prediction model\n",
    "    if resume:\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(os.path.join(SNAPSHOTS_DIR, 'custom_resnet50_lolle_resume_imgnet_{epoch:02d}.h5'), verbose=1, period=5)\n",
    "    else:\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(os.path.join(SNAPSHOTS_DIR, 'custom_resnet50_imgnet_{epoch:02d}.h5'), verbose=1, period=5)\n",
    "\n",
    "    #checkpoint = RedirectModel(checkpoint, model)\n",
    "    callbacks.append(checkpoint)\n",
    "    \n",
    "    #Visualisation of weights\n",
    "    vis_weights = None\n",
    "    if resume:\n",
    "        vis_weights = save_weights_vis(os.path.join(SNAPSHOTS_DIR, 'custom_resnet50_resume_imgnet_{}.png'))\n",
    "    else:\n",
    "        vis_weights = save_weights_vis(os.path.join(SNAPSHOTS_DIR, 'custom_resnet50_imgnet_{}.png'))\n",
    "    callbacks.append(vis_weights)\n",
    "    \n",
    "    #Reduce learning rate on plateu (tidligere loss, val_loss)\n",
    "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, verbose=1, mode='auto', cooldown=0, min_lr=0.001)\n",
    "    #callbacks.append(lr_scheduler)\n",
    "    \n",
    "    #Early stop\n",
    "    early_stop = EarlyStopping(monitor='loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "    callbacks.append(early_stop)\n",
    "    \n",
    "    #For tensorboard\n",
    "    tensorboard_callb = keras.callbacks.TensorBoard(log_dir=LOGS_DIR, histogram_freq=0, batch_size=batch_size, \n",
    "                                                    write_graph=True, write_grads=False, write_images=True, \n",
    "                                                    embeddings_freq=0, embeddings_layer_names=None, \n",
    "                                                    embeddings_metadata=None)\n",
    "    callbacks.append(tensorboard_callb)\n",
    "    \n",
    "    #Evaluation for the test/train set\n",
    "    evaluation_test = Evaluate(test_generator, tensorboard=tensorboard_callb, verbose=0, train=False)\n",
    "    evaluation_test = RedirectModel(evaluation_test, prediction_model)\n",
    "    callbacks.append(evaluation_test)\n",
    "    evaluation_train = Evaluate(train_generator, tensorboard=tensorboard_callb, verbose=0, train=True)\n",
    "    evaluation_train = RedirectModel(evaluation_train, prediction_model)\n",
    "    callbacks.append(evaluation_train)\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/madspoderpetersen/deep-traffic/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Epoch 1/75\n",
      "151/151 [==============================] - 154s 1s/step - loss: 5.0118 - regression_loss: 3.8443 - classification_loss: 1.1675\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_1.png\n",
      "Epoch 2/75\n",
      "151/151 [==============================] - 135s 894ms/step - loss: 4.1993 - regression_loss: 3.2981 - classification_loss: 0.9012\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_2.png\n",
      "Epoch 3/75\n",
      "151/151 [==============================] - 135s 894ms/step - loss: 3.5637 - regression_loss: 2.9377 - classification_loss: 0.6259\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_3.png\n",
      "Epoch 4/75\n",
      "151/151 [==============================] - 135s 896ms/step - loss: 3.0070 - regression_loss: 2.4394 - classification_loss: 0.5676\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_4.png\n",
      "Epoch 5/75\n",
      "151/151 [==============================] - 135s 897ms/step - loss: 2.5032 - regression_loss: 1.9776 - classification_loss: 0.5256\n",
      "\n",
      "Epoch 00005: saving model to /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_05.h5\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_5.png\n",
      "Epoch 6/75\n",
      "151/151 [==============================] - 135s 896ms/step - loss: 2.2098 - regression_loss: 1.7049 - classification_loss: 0.5049\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_6.png\n",
      "Epoch 7/75\n",
      "151/151 [==============================] - 135s 893ms/step - loss: 1.9675 - regression_loss: 1.4841 - classification_loss: 0.4833\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_7.png\n",
      "Epoch 8/75\n",
      "151/151 [==============================] - 135s 894ms/step - loss: 1.8145 - regression_loss: 1.3506 - classification_loss: 0.4639\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_8.png\n",
      "Epoch 9/75\n",
      "151/151 [==============================] - 135s 892ms/step - loss: 1.6264 - regression_loss: 1.1814 - classification_loss: 0.4450\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_9.png\n",
      "Epoch 10/75\n",
      "151/151 [==============================] - 135s 892ms/step - loss: 1.4913 - regression_loss: 1.0663 - classification_loss: 0.4250\n",
      "\n",
      "Epoch 00010: saving model to /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_10.h5\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_10.png\n",
      "Epoch 11/75\n",
      "151/151 [==============================] - 135s 893ms/step - loss: 1.3976 - regression_loss: 0.9930 - classification_loss: 0.4046\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_11.png\n",
      "Epoch 12/75\n",
      "151/151 [==============================] - 135s 894ms/step - loss: 1.2882 - regression_loss: 0.9028 - classification_loss: 0.3853\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_12.png\n",
      "Epoch 13/75\n",
      "151/151 [==============================] - 135s 893ms/step - loss: 1.2373 - regression_loss: 0.8721 - classification_loss: 0.3653\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_13.png\n",
      "Epoch 14/75\n",
      "151/151 [==============================] - 134s 890ms/step - loss: 1.1348 - regression_loss: 0.7871 - classification_loss: 0.3477\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_14.png\n",
      "Epoch 15/75\n",
      "151/151 [==============================] - 135s 892ms/step - loss: 1.0783 - regression_loss: 0.7428 - classification_loss: 0.3355\n",
      "\n",
      "Epoch 00015: saving model to /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_15.h5\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_15.png\n",
      "Epoch 16/75\n",
      "151/151 [==============================] - 135s 894ms/step - loss: 1.0233 - regression_loss: 0.7038 - classification_loss: 0.3195\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_16.png\n",
      "Epoch 17/75\n",
      "151/151 [==============================] - 135s 892ms/step - loss: 1.0295 - regression_loss: 0.7255 - classification_loss: 0.3040\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_17.png\n",
      "Epoch 18/75\n",
      "151/151 [==============================] - 135s 892ms/step - loss: 0.9484 - regression_loss: 0.6568 - classification_loss: 0.2916\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_18.png\n",
      "Epoch 19/75\n",
      "151/151 [==============================] - 135s 892ms/step - loss: 0.8939 - regression_loss: 0.6211 - classification_loss: 0.2728\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_19.png\n",
      "Epoch 20/75\n",
      "151/151 [==============================] - 135s 894ms/step - loss: 0.8841 - regression_loss: 0.6311 - classification_loss: 0.2530\n",
      "\n",
      "Epoch 00020: saving model to /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_20.h5\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_20.png\n",
      "Epoch 21/75\n",
      "151/151 [==============================] - 135s 893ms/step - loss: 0.8375 - regression_loss: 0.6035 - classification_loss: 0.2340\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_21.png\n",
      "Epoch 22/75\n",
      "151/151 [==============================] - 135s 894ms/step - loss: 0.7856 - regression_loss: 0.5743 - classification_loss: 0.2113\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_22.png\n",
      "Epoch 23/75\n",
      "151/151 [==============================] - 135s 896ms/step - loss: 0.8006 - regression_loss: 0.6090 - classification_loss: 0.1917\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_23.png\n",
      "Epoch 24/75\n",
      "151/151 [==============================] - 135s 894ms/step - loss: 0.7825 - regression_loss: 0.5988 - classification_loss: 0.1837\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_24.png\n",
      "Epoch 25/75\n",
      "151/151 [==============================] - 135s 893ms/step - loss: 0.7136 - regression_loss: 0.5442 - classification_loss: 0.1694\n",
      "\n",
      "Epoch 00025: saving model to /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_25.h5\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_25.png\n",
      "Epoch 26/75\n",
      "151/151 [==============================] - 135s 893ms/step - loss: 0.6961 - regression_loss: 0.5366 - classification_loss: 0.1595\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_26.png\n",
      "Epoch 27/75\n",
      "151/151 [==============================] - 135s 895ms/step - loss: 0.6905 - regression_loss: 0.5355 - classification_loss: 0.1550\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_27.png\n",
      "Epoch 28/75\n",
      "151/151 [==============================] - 135s 897ms/step - loss: 0.6434 - regression_loss: 0.4963 - classification_loss: 0.1471\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_28.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/75\n",
      "151/151 [==============================] - 135s 896ms/step - loss: 0.6346 - regression_loss: 0.4861 - classification_loss: 0.1484\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_29.png\n",
      "Epoch 30/75\n",
      "151/151 [==============================] - 135s 894ms/step - loss: 0.5843 - regression_loss: 0.4534 - classification_loss: 0.1309\n",
      "\n",
      "Epoch 00030: saving model to /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_30.h5\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_30.png\n",
      "Epoch 31/75\n",
      "151/151 [==============================] - 135s 896ms/step - loss: 0.5870 - regression_loss: 0.4523 - classification_loss: 0.1347\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_31.png\n",
      "Epoch 32/75\n",
      "151/151 [==============================] - 135s 896ms/step - loss: 0.5815 - regression_loss: 0.4539 - classification_loss: 0.1276\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_32.png\n",
      "Epoch 33/75\n",
      "151/151 [==============================] - 135s 897ms/step - loss: 0.5663 - regression_loss: 0.4472 - classification_loss: 0.1190\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_33.png\n",
      "Epoch 34/75\n",
      "151/151 [==============================] - 135s 894ms/step - loss: 0.5501 - regression_loss: 0.4363 - classification_loss: 0.1138\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_34.png\n",
      "Epoch 35/75\n",
      "151/151 [==============================] - 135s 895ms/step - loss: 0.5263 - regression_loss: 0.4146 - classification_loss: 0.1117\n",
      "\n",
      "Epoch 00035: saving model to /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_35.h5\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_35.png\n",
      "Epoch 36/75\n",
      "151/151 [==============================] - 135s 895ms/step - loss: 0.5143 - regression_loss: 0.4030 - classification_loss: 0.1113\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_36.png\n",
      "Epoch 37/75\n",
      "151/151 [==============================] - 135s 896ms/step - loss: 0.5364 - regression_loss: 0.4274 - classification_loss: 0.1090\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_37.png\n",
      "Epoch 38/75\n",
      "151/151 [==============================] - 135s 894ms/step - loss: 0.5092 - regression_loss: 0.4061 - classification_loss: 0.1031\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_38.png\n",
      "Epoch 39/75\n",
      "151/151 [==============================] - 135s 894ms/step - loss: 0.4976 - regression_loss: 0.3961 - classification_loss: 0.1015\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_39.png\n",
      "Epoch 40/75\n",
      "151/151 [==============================] - 135s 893ms/step - loss: 0.4791 - regression_loss: 0.3855 - classification_loss: 0.0936\n",
      "\n",
      "Epoch 00040: saving model to /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_40.h5\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_40.png\n",
      "Epoch 41/75\n",
      "151/151 [==============================] - 135s 893ms/step - loss: 0.4520 - regression_loss: 0.3617 - classification_loss: 0.0902\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_41.png\n",
      "Epoch 42/75\n",
      "151/151 [==============================] - 135s 894ms/step - loss: 0.4382 - regression_loss: 0.3457 - classification_loss: 0.0925\n",
      "Saving visualised weights of conv1 to file: /home/madspoderpetersen/deep-traffic/snapshots/custom_resnet50_imgnet_42.png\n",
      "155/604\r"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "training_type = TrainingType.IMGNET\n",
    "batch_size = 4\n",
    "\n",
    "keras.backend.tensorflow_backend.set_session(get_session())\n",
    "train_generator = create_train_generator(batch_size)\n",
    "test_generator = create_test_generator(batch_size)\n",
    "resume = False\n",
    "\n",
    "#From start\n",
    "if training_type == TrainingType.SCRATCH:\n",
    "    model, prediction_model = create_models(num_classes=train_generator.num_classes(), weights=None)\n",
    "#From imagenet\n",
    "elif training_type == TrainingType.IMGNET:\n",
    "    model, prediction_model = create_models(num_classes=train_generator.num_classes(), weights=\"imagenet\")\n",
    "#From earlier \n",
    "elif training_type == TrainingType.RESUME:\n",
    "    #snapshot = os.path.join(SNAPSHOTS_DIR, \"custom_resnet50_10.h5\")\n",
    "    snapshot = os.path.join(SNAPSHOTS_DIR, \"custom_resnet50_lolle_06.h5\")\n",
    "    resume = True\n",
    "    model, prediction_model = create_models(num_classes=train_generator.num_classes(), weights=snapshot)\n",
    "\n",
    "callbacks = create_callbacks(model, prediction_model, batch_size, test_generator, train_generator, resume)\n",
    "\n",
    "model.trainable = True\n",
    "\n",
    "# start training\n",
    "model.fit_generator(\n",
    "    generator = train_generator,\n",
    "    #steps_per_epoch = 850,\n",
    "    steps_per_epoch = math.floor(train_generator.size()/batch_size),\n",
    "    epochs = 75,\n",
    "    verbose = 1,\n",
    "    #workers=6,\n",
    "    #validation_data=test_generator,\n",
    "    #validation_steps=math.floor(test_generator.size()/batch_size),\n",
    "    callbacks = callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras_retinanet.models import load_model, backbone, resnet\n",
    "from keras_retinanet.utils.image import read_image_bgr\n",
    "from shared import get_session\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Get weights from conv1 layer\n",
    "weights = np.asarray(model.get_layer('conv1').get_weights())\n",
    "fig, ax = plt.subplots(figsize=(10, 10),nrows=8, ncols=8)\n",
    "for i, ax in enumerate(ax.reshape(-1)):\n",
    "    imgArray = weights[0,:,:,:,i]\n",
    "    # unity-based normalization https://datascience.stackexchange.com/a/5888\n",
    "    imgArray = (imgArray - np.min(imgArray)) / (np.max(imgArray) - np.min(imgArray))\n",
    "    ax.imshow(imgArray)\n",
    "    ax.axis('off')\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
